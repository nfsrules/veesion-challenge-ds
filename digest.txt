Directory structure:
└── veesion-challenge-ds/
    ├── README.md
    ├── main.py
    ├── requirements.txt
    ├── data/
    ├── optimizer/
    │   ├── __init__.py
    │   ├── base_models.py
    │   ├── global_optim.py
    │   ├── io_utils.py
    │   ├── local_optim.py
    │   ├── viz_utils.py
    │   └── __pycache__/
    ├── results/
    └── tests/
        └── __init__.py

================================================
File: README.md
================================================
# Veesion Data Science Challenge

This is my solution to the Data Science technical test. For maintenability and better usage 


## Directory Structure
```text version-challenge-ds/ ├── README.md # Project overview and instructions ├── main.py # Command-line script for Q3 and Q4 ├── requirements.txt # Dependencies ├── data/ # Input dataset (not included) ├── optimizer/ │ ├── __init__.py │ ├── base_models.py # Abstract base classes for camera and multi-camera optimizers │ ├── global_optim.py # Multi-camera optimization (Q3) │ ├── io_utils.py # Functions to load the dataset │ └── local_optim.py # Single-camera optimization model (Q3) ├── results/ # Optimization results ├── tests/ # Unit tests (out of scope due to time constraints) └── __init__.py ``` 

## Answers

### Question 1: Plot #FP vs. Recall curves for each camera and save as separate images.
- **Answer**: Refer to the (`analysis_notebook.ipynb`). The notebook includes data exploration, curve generation using `matplotlib`, and saving plots to the `results/` directory.

### Question 2: Analyze the model's performaance uniformness across cameras
- **Answer**: Refer to Section 2 of the Jupyter notebook (`analysis_notebook.ipynb`).

### Question 3: Optimization: Find an optimal per-camera threshold to reduce the total #FP by a target, without loosing too mane #TP.
- **Greedy/Naive implementations**: 
  - **Camera-level**: Select the threshold that minimizes the #TP lost per #FP avoided (reduce false alarms without loosing too much real theft). Implemented in `optimizer/local_optim.py` (`_fit_cost`).
  - **Multi-camera level**: Sort the cameras by cost ratio (TP lost / FP saved) and optimize them iterativelly until reaching the target #FP reduction. Implemented in `optimizer/global_optim.py` (`MultiCameraOptimizer`).
  - **Running the solution**:
        `python main.py --source data/production_alerts_meta_data.csv --target_fp_reduction 12000 --save_path results/optim.json`

 - **Smarter implementations**: 
  - **Camera-level**: 
  - **Multi-camera level**: 

### Question 4: Deployment: Making sure the code is simple to deploy
- **Task**: Prepare the script for deployment with flexible data sources, command-line execution, and single-camera support.
- **Implementation**: 
  - **CLI**: `main.py` using `argparse` for CL execution at multi and single camera level.
  - **Loging**: Added basic loging support.
  - **Data Source**: `optimizer/io_utils.py` includes a `DataLoader` class (support only CSV now for lack of time).
  - **Outputs**: Stateless camera and multi camera optimization classes with easy serializable JSON results `--save_path`. This make easier the future use of DBs (i.e., MongoDB, firestore, supabase...)
  - **Running the solution**:
        `python main.py --source data/production_alerts_meta_data.csv --store be-ad-1420-hugo-3 --camera_id 10 --target_fp_reduction 150 --save_path results/camera_optim.json`

## Setup
1. **Install dependencies**:
   ```bash
   pip install -r requirements.txt


================================================
File: main.py
================================================
import argparse
import logging
import os
from optimizer.io_utils import DataLoader
from optimizer import CameraModel, MultiCameraOptimizer

logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(name)s - %(message)s")

def main(args):
    """
    Main entry point for running the multi-camera optimization.

    Steps:
        1. Load data from --source.
        2. Filter for a single camera if --store and --camera_id are provided.
        3. Run optimization with the requested --target_fp_reduction.
        4. Save results if --save_path is specified.
    """
    try:
        df = DataLoader(args.source, source_type=args.source_type).load()
    except Exception as e:
        logging.error(f"Failed to load data: {e}")
        return

    if args.camera_id:
        if not args.store:
            logging.error("Must provide --store when using --camera_id")
            return
        df = df[(df['store'] == args.store) & (df['camera_id'] == args.camera_id)]
        if df.empty:
            logging.error(f"No data found for store '{args.store}' and camera_id '{args.camera_id}'")
            return
        logging.info(f"Running optimization for store '{args.store}', camera_id '{args.camera_id}'")
    else:
        logging.info("Running optimization for all cameras")

    optimizer = MultiCameraOptimizer(df, CameraModel)
    optimizer.run(target_fp_reduction=args.target_fp_reduction, strategy=args.strategy)

    if args.save_path:
        os.makedirs(os.path.dirname(args.save_path), exist_ok=True)
        optimizer.save(args.save_path)
        logging.info(f"Saved optimizer state to {args.save_path}")

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Run Multi-Camera Optimizer")
    parser.add_argument(
        "--source", type=str, required=True,
        help="Data source (e.g., CSV path)"
    )
    parser.add_argument(
        "--source_type", type=str, choices=["csv"], default="csv",
        help="Type of data source (default: csv)"
    )
    parser.add_argument(
        "--target_fp_reduction", type=int, default=100,
        help="Desired number of false positives to reduce globally (default: 100)"
    )
    parser.add_argument(
        "--strategy", type=str, choices=["greedy", "lazy"], default="lazy",
        help="Optimization strategy: 'greedy' or 'lazy'. Default is 'lazy'."
    )
    parser.add_argument(
        "--store", type=str,
        help="Store name (required if --camera_id is provided)"
    )
    parser.add_argument(
        "--camera_id", type=str,
        help="Camera ID (e.g., '1') to run for a single camera; requires --store"
    )
    parser.add_argument(
        "--save_path", type=str, default="",
        help="Path to save the optimizer's results (JSON). If empty, results won't be saved."
    )
    parser.add_argument(
        "--quiet", action="store_true",
        help="Suppress detailed logs"
    )

    args = parser.parse_args()
    main(args)



================================================
File: requirements.txt
================================================
numpy
pandas
scikit-learn



================================================
File: optimizer/__init__.py
================================================
from .global_optim import MultiCameraOptimizer 
from .local_optim import CameraModel


================================================
File: optimizer/base_models.py
================================================
from abc import ABC, abstractmethod
from datetime import datetime


class BaseCameraModel(ABC):
    """
    Abstract base class for all camera models.
    Defines the interface for training, prediction, evaluation, and persistence.
    """

    def __init__(self, camera_id, store=None):
        self.camera_id = str(camera_id)
        self.store = store
        self.threshold = 0.0
        self.optim_method = None
        self._fitted = False
        self.cost_ratio = float("inf") 
        self.created_at = datetime.now()
        self.updated_at = self.created_at

    @abstractmethod
    def fit(self, X, y, method="greedy", **kwargs):
        pass

    @abstractmethod
    def predict(self, X):
        pass

    @abstractmethod
    def save(self, path):
        pass

    @classmethod
    @abstractmethod
    def load(cls, path):
        pass

    def __repr__(self):
        return (f"{self.__class__.__name__}(cam={self.camera_id}, th={self.threshold:.2f}, "
                f"method={self.optim_method}, updated={self.updated_at.strftime('%Y-%m-%d %H:%M:%S')})")


class BaseGlobalOptimizer(ABC):
    """
    Abstract base class for global optimizers.
    Defines the interface for runing an optimization with a target #FP reduction and persistence.
    """
    @abstractmethod
    def run(self, target_fp_reduction: int, outdir: str = None):
        pass

    @abstractmethod
    def save(self, path: str):
        pass

    @classmethod
    @abstractmethod
    def load(cls, path: str):
        pass




================================================
File: optimizer/global_optim.py
================================================
import json
import logging
import time

from .base_models import BaseGlobalOptimizer

logger = logging.getLogger(__name__)


class MultiCameraOptimizer(BaseGlobalOptimizer):
    def __init__(self, df, camera_model_cls, verbose=True):
        self.df = df
        self.camera_model_cls = camera_model_cls
        self.verbose = verbose

        self.cameras_info = []
        self.selected = []
        self.skipped = []
        self.total_fp_saved = 0
        self.total_tp_lost = 0
        self.target_fp_reduction = None

        if not self.verbose:
            logger.setLevel(logging.WARNING)

    def _fit_camera(self, store, cam_id, group, method="cost", verbose=False):
        """
        Fit and evaluate a single camera, returning gain info if valid.
        """
        X = group["probability"].values.astype(float)
        y = group["is_theft"].values
        camera_name = f"{store}_cam{cam_id}"
        camera = self.camera_model_cls(camera_id=camera_name)

        try:
            camera.fit(X, y, method=method, verbose=verbose)
            gain = camera.report_gain()

            if gain["fp_saved"] <= 0:
                self.skipped.append(camera_name)
                return None

            return {
                "camera_id": camera_name,
                "fp_saved": gain["fp_saved"],
                "tp_lost": gain["tp_lost"],
                "cost_ratio": camera.cost_ratio,
                "threshold": camera.threshold,
            }
        
        except Exception as e:
            logger.warning(f"Error fitting camera {camera_name}: {e}")
            self.skipped.append(camera_name)
            return None

    def _fit_cameras(self, method):
        for (store, cam_id), group in self.df.groupby(['store', 'camera_id']):
            cam_info = self._fit_camera(store, cam_id, group, method=method, verbose=self.verbose)
            if cam_info:
                self.cameras_info.append(cam_info)
     
    def run(self, target_fp_reduction: int, strategy: str = "greedy"):
        assert strategy in ["greedy", "lazy"], "Strategy must be 'greedy' or 'lazy'"

        logger.info(f"Running {strategy} optimization...")

        if strategy == "lazy":
            self._lazy_run(target_fp_reduction)
        else:
            self._greedy_run(target_fp_reduction)

    def _greedy_run(self, target_fp_reduction: int, method: str = "cost"):
        assert method in ['cost', 'optuna']
        start_time = time.time()

        self.target_fp_reduction = target_fp_reduction

        if not self.cameras_info:
            self._fit_cameras(method)

        self.cameras_info.sort(key=lambda x: x["cost_ratio"])

        self.selected = []
        self.total_fp_saved = 0
        self.total_tp_lost = 0

        for cam in self.cameras_info:
            if self.total_fp_saved >= target_fp_reduction:
                break
            self.selected.append(cam["camera_id"])
            self.total_fp_saved += cam["fp_saved"]
            self.total_tp_lost += cam["tp_lost"]

        elapsed = time.time() - start_time

        summary = (
            "\nOptimization Summary\n"
            f"Target FP reduction : {self.target_fp_reduction}\n"
            f"Total FP saved      : {self.total_fp_saved}\n"
            f"Total TP lost       : {self.total_tp_lost}\n"
            f"Used                : {len(self.selected)} / {len(self.cameras_info)} cameras"
            f"Total optimization time: {elapsed:.6f} seconds"
        )
        if self.skipped:
            summary += f"\nSkipped cameras      : {self.skipped}"

        logger.info(summary)

    def _lazy_run(self, target_fp_reduction: int, method: str = "cost"):
        start_time = time.time()
        self.target_fp_reduction = target_fp_reduction

        grouped = self.df.groupby(["store", "camera_id"])

        # Let's preselect the cameras that have an high numeber of normal events
        # Because they're likelly to produce a lot of FP.
        # We need to pay more attention to those.
        priority_list = []
        for (store, cam_id), group in grouped:
            baseline_fp = (group["is_theft"] == 0).sum()
            priority_list.append(((store, cam_id), baseline_fp))

        priority_list.sort(key=lambda x: -x[1])

        self.selected = []
        self.total_fp_saved = 0
        self.total_tp_lost = 0
        self.cameras_info = []
        self.skipped = []

        for (store, cam_id), _ in priority_list:

            # Let's fit thresholds until we get the target reduction
            if self.total_fp_saved >= target_fp_reduction:
                break

            group = grouped.get_group((store, cam_id))
            cam_info = self._fit_camera(store, cam_id, group, method=method, verbose=self.verbose)

            if cam_info:
                self.cameras_info.append(cam_info)
                self.selected.append(cam_info["camera_id"])
                self.total_fp_saved += cam_info["fp_saved"]
                self.total_tp_lost += cam_info["tp_lost"]

        elapsed = time.time() - start_time

        summary = (
            "\n[Lazy Greedy Optimization Summary]\n"
            f"Target FP reduction : {self.target_fp_reduction}\n"
            f"Total FP saved      : {self.total_fp_saved}\n"
            f"Total TP lost       : {self.total_tp_lost}\n"
            f"Used                : {len(self.selected)} cameras\n"
            f"Skipped             : {len(self.skipped)} cameras\n"
            f"Total optimization time: {elapsed:.4f} seconds"
        )
        logger.info(summary)

    def to_dict(self):
        return {
            "target_fp_reduction": int(self.target_fp_reduction),
            "total_fp_saved": int(self.total_fp_saved),
            "total_tp_lost": int(self.total_tp_lost),
            "cameras_info": self.cameras_info
        }

    @classmethod
    def from_dict(cls, data, df):
        obj = cls(df)
        obj.__dict__.update(data)
        return obj

    def save(self, path: str):
        with open(path, "w") as f:
            json.dump(self.to_dict(), f, indent=2)

    @classmethod
    def load(cls, path: str, df):
        with open(path, "r") as f:
            return cls.from_dict(json.load(f), df)

    def __repr__(self):
        return (f"<GreedyCameraSelector target={self.target_fp_reduction} "
                f"| FP saved={self.total_fp_saved}, TP lost={self.total_tp_lost}, "
                f"selected={len(self.selected)}, skipped={len(self.skipped)}>")



================================================
File: optimizer/io_utils.py
================================================
# optimizer/io_utils.py
import os
import pandas as pd
import logging
from typing import Optional, List

logger = logging.getLogger(__name__)

DEFAULT_THEFT_LABELS = [
    'Suspicious Bag', 'Suspicious', 'Theft',
    'Gesture Into Body', 'Product Into Stroller'
]

class DataLoader:
    def __init__(self, source: str, source_type: str = "csv", theft_labels: Optional[List[str]] = None):
        """
        Flexible data loader.

        Args:
            source (str): File path or connection string.
            source_type (str): One of ['csv'].
            theft_labels (List[str], optional): Override default labels.
        """
        self.source = source
        self.source_type = source_type
        self.theft_labels = theft_labels or DEFAULT_THEFT_LABELS

    def load(self) -> pd.DataFrame:
        if self.source_type == "csv":
            return self._load_csv()
        else:
            raise ValueError(f"Unsupported source_type: {self.source_type}")

    def _load_csv(self) -> pd.DataFrame:
        if not os.path.exists(self.source):
            raise FileNotFoundError(f"File not found: {self.source}")
        
        logger.info(f"Loading CSV from {self.source}")
        df = pd.read_csv(self.source, delimiter=";", index_col=0)

        if 'label' not in df.columns or 'video_name' not in df.columns:
            raise ValueError("Missing required columns: 'label' and/or 'video_name'")

        df.dropna(inplace=True)
        df['is_theft'] = df['label'].isin(self.theft_labels).astype(int)
        df['camera_id'] = df['video_name'].str.extract(r'camera_(\d+)_ip')

        if df['camera_id'].isnull().any():
            logger.warning("Some rows had missing or unparsable camera_id values.")

        return df



================================================
File: optimizer/local_optim.py
================================================
import os
import json
import numpy as np
import logging
from datetime import datetime
from sklearn.metrics import precision_score, recall_score, f1_score, precision_recall_curve
import optuna

from .base_models import BaseCameraModel

logger = logging.getLogger(__name__)


class CameraModel(BaseCameraModel):
    """
    A threshold-based model for a single camera that learns an optimal threshold
    to classify theft events using a selected optimization strategy with included persistence.
    """

    def fit(self, X, y, method="cost", verbose=True):
        """
        Fit camera prediction model by selecting an optimal threshold based on prediction scores and labels.

        Available methods:
            - 'cost': Minimizes true positives lost per false positive saved.
                Optional kwargs:
                    - steps (int): Number of thresholds to evaluate (default: 500)
            - 'optuna': Greedily increases threshold to reduce cost until no further improvement.
                Optional kwargs:
                    - steps (int): Number of thresholds to evaluate (default: 500)

        Time Complexity:
            O(T × n), where:
                T = number of thresholds (default 500 or as set by `steps`)
                n = number of samples

        Args:
            X (np.ndarray): Prediction scores (probabilities), shape (n_samples,).
            y (np.ndarray): Binary labels (1 = theft, 0 = non-theft), shape (n_samples,).
            method (str): Optimization strategy to use ('cost' or 'greedy').
            **kwargs: Additional arguments passed to the selected method.
        """
        self.optim_method = method
        self._fitted = False

        self.baseline_tp, self.baseline_fp = self._compute_tp_fp(X, y, threshold=self.threshold)

        if method == "cost":
            best_th = self._fit_cost(X, y)
        elif method == "optuna":
            best_th = self._fit_optuna(X, y, n_trials=50)
        else:
            raise ValueError(f"Unknown optimization method: {method}")

        self.threshold = best_th
        self.optimal_tp, self.optimal_fp = self._compute_tp_fp(X, y, threshold=best_th)
        self.tp_lost = self.baseline_tp - self.optimal_tp
        self.fp_saved = self.baseline_fp - self.optimal_fp
        self.cost_ratio = self._compute_cost_ratio(self.tp_lost, self.fp_saved)

        self._fitted = True
        self.updated_at = datetime.now()

        if verbose:
            logger.info(
                f"Fitted camera {self.camera_id[:-5]}. "
                f"Optimal th: {round(self.threshold, 4)}. "
                f"FP saved: {self.fp_saved}, TP lost: {self.tp_lost}"
            )

    def _compute_cost_ratio(self, tp_lost, fp_saved):
        """Compute the cost as true positives lost per false positive saved."""
        return float("inf") if fp_saved <= 0 else tp_lost / (fp_saved + 1e-8)

    def _fit_cost(self, X, y):
        """Grid search for optimal threshold minimizing TP lost / FP saved."""
        base_tp, base_fp = self._compute_tp_fp(X, y, threshold=self.threshold)

        if base_fp == 0 or base_tp == 0:
            return self.threshold

        precision, recall, thresholds = precision_recall_curve(y, X)
        total_pos = np.sum(y)

        best_score = np.inf
        best_th = self.threshold

        for i in range(len(thresholds)):
            tp = recall[i] * total_pos

            # invert precision = TP / (TP + FP) to get FP
            fp = tp * (1 - precision[i]) / (precision[i] + 1e-8)

            delta_tp = base_tp - tp
            delta_fp = base_fp - fp

            if delta_fp <= 0:
                continue

            cost = delta_tp / (delta_fp + 1e-8)
            if cost < best_score or (cost == best_score and thresholds[i] > best_th):
                best_score = cost
                best_th = thresholds[i]

        return best_th

    def _fit_optuna(self, X, y, n_trials=100):
        base_tp, base_fp = self.baseline_tp, self.baseline_fp

        def objective(trial):
            threshold = trial.suggest_float("threshold", 0.0, 1.0)
            tp, fp = self._compute_tp_fp(X, y, threshold)
            delta_tp = base_tp - tp
            delta_fp = base_fp - fp
            if delta_fp <= 0:
                return float("inf")
            return delta_tp / (delta_fp + 1e-8)

        study = optuna.create_study(direction="minimize")
        study.optimize(objective, n_trials=n_trials)
        return study.best_params["threshold"]

    def _apply_threshold(self, X, threshold):
        """Apply binary threshold to scores."""
        return (X >= threshold).astype(int)

    def _compute_tp_fp(self, X, y, threshold):
        """Compute true positives and false positives for given threshold."""
        preds = self._apply_threshold(X, threshold)
        tp = np.sum((preds == 1) & (y == 1))
        fp = np.sum((preds == 1) & (y == 0))
        return tp, fp

    def report_gain(self):
        """Return dict of TP/FP gain/loss and selected threshold."""
        if not self._fitted:
            raise RuntimeError("Model must be fit before reporting gain.")
        return {
            "baseline_tp": int(self.baseline_tp),
            "baseline_fp": int(self.baseline_fp),
            "optimal_tp": int(self.optimal_tp),
            "optimal_fp": int(self.optimal_fp),
            "tp_lost": int(self.tp_lost),
            "fp_saved": int(self.fp_saved),
            "threshold": float(self.threshold),
            "cost_method": self.optim_method,
            "cost_ratio": float(self.cost_ratio)
        }

    def predict(self, X):
        """Return binary predictions using the fitted threshold."""
        if not self._fitted:
            raise RuntimeError("Model must be fit before predicting.")
        return self._apply_threshold(X, self.threshold)

    def score(self, X, y, metric="recall"):
        """
        Compute a classification metric.

        Args:
            X (np.ndarray): Scores, shape (n_samples,).
            y (np.ndarray): Labels, shape (n_samples,).
            metric (str): 'recall', 'precision', or 'f1'.

        Returns:
            float: Metric score.
        """
        if not self._fitted:
            raise RuntimeError("Model must be fit before scoring.")
        preds = self.predict(X)

        if metric == "recall":
            return recall_score(y, preds, zero_division=0)
        elif metric == "precision":
            return precision_score(y, preds, zero_division=0)
        elif metric == "f1":
            return f1_score(y, preds, zero_division=0)
        else:
            raise ValueError(f"Unsupported metric: {metric}")

    def to_dict(self):
        """Serialize model to dictionary."""
        return {
            "camera_id": self.camera_id,
            "threshold": self.threshold,
            "cost_ratio": self.cost_ratio,
            "tp_lost": self.tp_lost,
            "fp_saved": self.fp_saved,
            "optim_method": self.optim_method,
            "updated_at": self.updated_at.isoformat()
        }

    @classmethod
    def from_dict(cls, data):
        """Deserialize model from dictionary."""
        obj = cls(camera_id=data["camera_id"])
        for attr in ["threshold", "cost_ratio", "tp_lost", "fp_saved", "optim_method"]:
            setattr(obj, attr, data[attr])
        obj.updated_at = datetime.fromisoformat(data["updated_at"])
        obj._fitted = True
        return obj

    def save(self, path):
        """Save model to disk as JSON."""
        os.makedirs(os.path.dirname(path), exist_ok=True)
        with open(path, "w") as f:
            json.dump(self.to_dict(), f, indent=2)

    @classmethod
    def load(cls, path):
        """Load model from disk."""
        with open(path, "r") as f:
            data = json.load(f)
        return cls.from_dict(data)

    def __repr__(self):
        return (f"{self.__class__.__name__}(cam={self.camera_id}, "
                f"th={self.threshold:.2f}, cost_ratio={self.cost_ratio:.4f}, "
                f"method={self.optim_method}, "
                f"updated={self.updated_at.strftime('%Y-%m-%d %H:%M:%S')})")



================================================
File: optimizer/viz_utils.py
================================================





================================================
File: tests/__init__.py
================================================


